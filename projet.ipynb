{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e1p-OilaAvNT"
   },
   "source": [
    "# MedBot\n",
    "\n",
    "### Miniprojet dans le cadre de l'UE \"Réseaux de neurones\" - M2 AMIS\n",
    "\n",
    "GODET Chloé et GROSJACQUES Marwane\n",
    "___________________________________\n",
    "\n",
    "## Pourquoi un chatbot médical ? \n",
    "\n",
    "Un chatbot médical pourrait être un outil précieux pour des patients. En effet, le fait que cet outil soit disponible 7j/7 et 24h/24 permettraient à ceux qui souhaitent poser leurs questions d'avoir un interlocuteur toujours disponible. De plus, pour les personnes vivant dans des zones isolées (dans les déserts médicaux notamment) ou ayant des difficultés à se déplacer, le chatbot peut représenter un premier contact pour obtenir des informations ou un premier avis avant de consulter un professionnel.\n",
    "\n",
    "Un chatbot peut analyser les réponses des utilisateurs et fournir des recommandations adaptées comme suggérer une consultation avec un spécialiste ou encore orienter vers un service d'urgence en cas de symptômes graves.\n",
    "Cependant, un chatbot médical ne remplace en aucun cas un médecin. Les diagnostics, traitements et décisions médicales doivent toujours être confiés à des professionnels de santé qualifiés.\n",
    "\n",
    "## Notre objectif\n",
    "\n",
    "Nous avons décidé de réaliser un chatbot médical (**MedBot**). Au vu de nos connaissances, du temps dont on dispose et surtout de nos ressources actuelles, nous savons que nous ne pouvons pas réaliser un chatbot réellement performant.\n",
    "\n",
    "L'objectif était, pour nous, de pouvoir lui donner un/des symptôme(s) et qu'il nous donne un diagnostic possible.\n",
    "Nous parlerons des améliorations possibles que nous aurions aimé implémenter à la fin de ce notebook.\n",
    "_________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importer le dataset\n",
    "\n",
    "Nous avons travaillé sur Google Colab tout au long de ce projet afin ed bénéficier du GPU que propose le site. En effet, lors de l'entraînement du modèle, l'utilisation seule du CPU n'était pas assez performante.\n",
    "\n",
    "La cellule suivante permet d'importer le dataset dans l'environnement de Google Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 137
    },
    "id": "KaOsk0FzzMyL",
    "outputId": "c70c7baa-fc8a-4c0a-e29a-3f2317e17c12"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-e1c8dac0-3cec-46bb-9dc6-b4d75bf36728\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-e1c8dac0-3cec-46bb-9dc6-b4d75bf36728\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script>// Copyright 2017 Google LLC\n",
       "//\n",
       "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
       "// you may not use this file except in compliance with the License.\n",
       "// You may obtain a copy of the License at\n",
       "//\n",
       "//      http://www.apache.org/licenses/LICENSE-2.0\n",
       "//\n",
       "// Unless required by applicable law or agreed to in writing, software\n",
       "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
       "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "// See the License for the specific language governing permissions and\n",
       "// limitations under the License.\n",
       "\n",
       "/**\n",
       " * @fileoverview Helpers for google.colab Python module.\n",
       " */\n",
       "(function(scope) {\n",
       "function span(text, styleAttributes = {}) {\n",
       "  const element = document.createElement('span');\n",
       "  element.textContent = text;\n",
       "  for (const key of Object.keys(styleAttributes)) {\n",
       "    element.style[key] = styleAttributes[key];\n",
       "  }\n",
       "  return element;\n",
       "}\n",
       "\n",
       "// Max number of bytes which will be uploaded at a time.\n",
       "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
       "\n",
       "function _uploadFiles(inputId, outputId) {\n",
       "  const steps = uploadFilesStep(inputId, outputId);\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  // Cache steps on the outputElement to make it available for the next call\n",
       "  // to uploadFilesContinue from Python.\n",
       "  outputElement.steps = steps;\n",
       "\n",
       "  return _uploadFilesContinue(outputId);\n",
       "}\n",
       "\n",
       "// This is roughly an async generator (not supported in the browser yet),\n",
       "// where there are multiple asynchronous steps and the Python side is going\n",
       "// to poll for completion of each step.\n",
       "// This uses a Promise to block the python side on completion of each step,\n",
       "// then passes the result of the previous step as the input to the next step.\n",
       "function _uploadFilesContinue(outputId) {\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  const steps = outputElement.steps;\n",
       "\n",
       "  const next = steps.next(outputElement.lastPromiseValue);\n",
       "  return Promise.resolve(next.value.promise).then((value) => {\n",
       "    // Cache the last promise value to make it available to the next\n",
       "    // step of the generator.\n",
       "    outputElement.lastPromiseValue = value;\n",
       "    return next.value.response;\n",
       "  });\n",
       "}\n",
       "\n",
       "/**\n",
       " * Generator function which is called between each async step of the upload\n",
       " * process.\n",
       " * @param {string} inputId Element ID of the input file picker element.\n",
       " * @param {string} outputId Element ID of the output display.\n",
       " * @return {!Iterable<!Object>} Iterable of next steps.\n",
       " */\n",
       "function* uploadFilesStep(inputId, outputId) {\n",
       "  const inputElement = document.getElementById(inputId);\n",
       "  inputElement.disabled = false;\n",
       "\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  outputElement.innerHTML = '';\n",
       "\n",
       "  const pickedPromise = new Promise((resolve) => {\n",
       "    inputElement.addEventListener('change', (e) => {\n",
       "      resolve(e.target.files);\n",
       "    });\n",
       "  });\n",
       "\n",
       "  const cancel = document.createElement('button');\n",
       "  inputElement.parentElement.appendChild(cancel);\n",
       "  cancel.textContent = 'Cancel upload';\n",
       "  const cancelPromise = new Promise((resolve) => {\n",
       "    cancel.onclick = () => {\n",
       "      resolve(null);\n",
       "    };\n",
       "  });\n",
       "\n",
       "  // Wait for the user to pick the files.\n",
       "  const files = yield {\n",
       "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
       "    response: {\n",
       "      action: 'starting',\n",
       "    }\n",
       "  };\n",
       "\n",
       "  cancel.remove();\n",
       "\n",
       "  // Disable the input element since further picks are not allowed.\n",
       "  inputElement.disabled = true;\n",
       "\n",
       "  if (!files) {\n",
       "    return {\n",
       "      response: {\n",
       "        action: 'complete',\n",
       "      }\n",
       "    };\n",
       "  }\n",
       "\n",
       "  for (const file of files) {\n",
       "    const li = document.createElement('li');\n",
       "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
       "    li.append(span(\n",
       "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
       "        `last modified: ${\n",
       "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
       "                                    'n/a'} - `));\n",
       "    const percent = span('0% done');\n",
       "    li.appendChild(percent);\n",
       "\n",
       "    outputElement.appendChild(li);\n",
       "\n",
       "    const fileDataPromise = new Promise((resolve) => {\n",
       "      const reader = new FileReader();\n",
       "      reader.onload = (e) => {\n",
       "        resolve(e.target.result);\n",
       "      };\n",
       "      reader.readAsArrayBuffer(file);\n",
       "    });\n",
       "    // Wait for the data to be ready.\n",
       "    let fileData = yield {\n",
       "      promise: fileDataPromise,\n",
       "      response: {\n",
       "        action: 'continue',\n",
       "      }\n",
       "    };\n",
       "\n",
       "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
       "    let position = 0;\n",
       "    do {\n",
       "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
       "      const chunk = new Uint8Array(fileData, position, length);\n",
       "      position += length;\n",
       "\n",
       "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
       "      yield {\n",
       "        response: {\n",
       "          action: 'append',\n",
       "          file: file.name,\n",
       "          data: base64,\n",
       "        },\n",
       "      };\n",
       "\n",
       "      let percentDone = fileData.byteLength === 0 ?\n",
       "          100 :\n",
       "          Math.round((position / fileData.byteLength) * 100);\n",
       "      percent.textContent = `${percentDone}% done`;\n",
       "\n",
       "    } while (position < fileData.byteLength);\n",
       "  }\n",
       "\n",
       "  // All done.\n",
       "  yield {\n",
       "    response: {\n",
       "      action: 'complete',\n",
       "    }\n",
       "  };\n",
       "}\n",
       "\n",
       "scope.google = scope.google || {};\n",
       "scope.google.colab = scope.google.colab || {};\n",
       "scope.google.colab._files = {\n",
       "  _uploadFiles,\n",
       "  _uploadFilesContinue,\n",
       "};\n",
       "})(self);\n",
       "</script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving dataset.csv to dataset.csv\n",
      "User uploaded file \"dataset.csv\" with length 30664 bytes\n"
     ]
    }
   ],
   "source": [
    "from google.colab import files\n",
    "\n",
    "uploaded = files.upload()\n",
    "\n",
    "for fn in uploaded.keys():\n",
    "  print('User uploaded file \"{name}\" with length {length} bytes'.format(name=fn, length=len(uploaded[fn])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H8iAdfpcBEBe"
   },
   "source": [
    "# Les librairies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voici toutes les librairies que nous avons utilisées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "nJfTvNMuzuZD"
   },
   "outputs": [],
   "source": [
    "import torch                    # module principal pour notre réseau de neurones\n",
    "import math                     # calcul du log pour le positional encoding\n",
    "import pickle                   # sauvegarde et chargement du tokenizer\n",
    "import pandas as pd             # lecture du dataset\n",
    "import matplotlib.pyplot as plt # dessine la courbe des epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VqzGxQt023DA"
   },
   "source": [
    "# Le modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme nous sommes curieux et que nous aimons comprendre dans sa globalité ce qu'on utilise, nous avons choisis d'implémenter notre modèle et de ne pas utiliser de modèle pré-entraîné. Nous avons utilisé le transformer de pytorch, mais nous avons réalisé notre propre tokenization, notre positionnal encoding et nous avons généré des tokens du chatbot. Nous expliquerons cela dans la suite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "pwA6C21lz_wl"
   },
   "outputs": [],
   "source": [
    "D_MODEL = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`D_MODEL` est la dimension de notre modèle, c'est à dire le nombre de tokens que nous pouvons donner en input à notre modèle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Le tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons décidé de faire notre propre tokenizer qui sera rempli avec les mots de notre dataset.\n",
    "Il est composé de 4 tokens spéciaux :\n",
    "- **PAD**, le padding\n",
    "- **CLS**, le début de la phrase\n",
    "- **SEP**, la fin de la phrase\n",
    "- **UNK**, lorsque le mot n'est pas connu et ne doit pas être ajouté au tokenizer\n",
    "\n",
    "Ensuite, chaque mot encodé avec le tokenizer permet de le remplir. En effet, si un mot n'est pas encore reconnu par le tokenizer, nous lui attribuons un nouveau token qui sera redonné à chaque apparition de ce mot.\n",
    "\n",
    "Le tokenizer permet d'**encoder** une phrase et de **décoder** une suite de tokens.\n",
    "\n",
    "Nous avons aussi implémenté la sauvegarde et le chargement du tokenizer afin de ne pas avoir à le reremplir à chaque fois."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "9KfSw2eIzwGh"
   },
   "outputs": [],
   "source": [
    "class Tokenizer:\n",
    "    pad_token_id = 0\n",
    "    pad_token = \"[PAD]\"\n",
    "    cls_token_id = 1\n",
    "    cls_token = \"[CLS]\"\n",
    "    sep_token_id = 2\n",
    "    sep_token = \"[SEP]\"\n",
    "    unk_token_id = 3\n",
    "    unk_token = \"[UNK]\"\n",
    "    special_tokens = [pad_token_id, cls_token_id, sep_token_id, unk_token_id]\n",
    "\n",
    "\n",
    "    def __init__(self, filename=None):\n",
    "        if filename:\n",
    "            with open(filename, 'rb') as file:\n",
    "                self.vocab = pickle.load(file)\n",
    "            self.next_token_id = max(self.vocab.values()) + 1\n",
    "            if len(self.vocab) != self.next_token_id:\n",
    "                print(\"Token(s) manquant(s) dans le vocabulaire\")\n",
    "                exit(1)\n",
    "\n",
    "        else:\n",
    "            self.vocab = {\n",
    "                    self.pad_token: self.pad_token_id,\n",
    "                    self.cls_token: self.cls_token_id,\n",
    "                    self.sep_token: self.sep_token_id,\n",
    "                    self.unk_token: self.unk_token_id\n",
    "            }\n",
    "            self.next_token_id = 4\n",
    "\n",
    "    def add_word(self, word):\n",
    "        self.vocab[word] = self.next_token_id\n",
    "        self.next_token_id += 1\n",
    "\n",
    "    def get_word(self, token):\n",
    "        if 0 <= token and token < self.next_token_id:\n",
    "            return list(self.vocab.keys())[list(self.vocab.values()).index(token)]\n",
    "        else:\n",
    "            exit(1)\n",
    "\n",
    "    def vocab_size(self):\n",
    "        return len(self.vocab)\n",
    "\n",
    "    def encode(self, text, size=D_MODEL, should_extend=False):\n",
    "        words = text.strip().lower().split(' ')\n",
    "        tokens = [self.cls_token_id]\n",
    "        for word in words:\n",
    "            if word in self.vocab.keys():\n",
    "                tokens.append(self.vocab[word])\n",
    "            elif should_extend:\n",
    "                self.add_word(word)\n",
    "                tokens.append(self.vocab[word])\n",
    "            else:\n",
    "                tokens.append(self.unk_token_id)\n",
    "\n",
    "        tokens.append(self.sep_token_id)\n",
    "\n",
    "        if len(tokens) > size: print(\"[WARNING] Phrase trop longue\")\n",
    "        while len(tokens) < size:\n",
    "            tokens.append(self.pad_token_id)\n",
    "\n",
    "        return tokens\n",
    "\n",
    "    def decode(self, tokens, skip_special_tokens=False):\n",
    "        if skip_special_tokens:\n",
    "            words = [self.get_word(token) for token in tokens if token not in self.special_tokens]\n",
    "        else:\n",
    "            words = [self.get_word(token) for token in tokens]\n",
    "\n",
    "        return \" \".join(words)\n",
    "\n",
    "    def save(self, filename):\n",
    "        with open(filename, 'wb') as file:\n",
    "            pickle.dump(self.vocab, file, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bzAm5JdKbSiu"
   },
   "source": [
    "## Positional Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pytorch ne propose pas de Positional Encoding, nous avons donc écrit notre propre Positional Encoding (celui vu en cours)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "oX2vwSTszwRV"
   },
   "outputs": [],
   "source": [
    "class PositionalEncoding(torch.nn.Module):\n",
    "    def __init__(self, d_model, max_len=100, dropout=0.1):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = torch.nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)  # sin sur indices pairs\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)  # cos sur indices impairs\n",
    "\n",
    "        self.register_buffer(\"pe\", pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:, :x.size(1), :]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notre modèle principal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "r79-7KuGzwNY"
   },
   "outputs": [],
   "source": [
    "class TransformerModel(torch.nn.Module):\n",
    "    def __init__(self, vocab_size, d_model=D_MODEL, nhead=8, num_encoder_layers=6, num_decoder_layers=6, dim_feedforward=2048, dropout=0.1):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(vocab_size, d_model)\n",
    "        self.positional_encoding = PositionalEncoding(d_model, dropout=dropout)\n",
    "        self.transformer = torch.nn.Transformer(d_model, nhead, num_encoder_layers, num_decoder_layers, dim_feedforward, dropout, batch_first=True)\n",
    "        self.fc_out = torch.nn.Linear(d_model, vocab_size)\n",
    "        self.src_pad_idx = None\n",
    "        self.nhead = nhead\n",
    "\n",
    "    def forward(self, src, tgt):\n",
    "        src_emb = self.positional_encoding(self.embedding(src))\n",
    "        tgt_emb = self.positional_encoding(self.embedding(tgt))\n",
    "        tgt_mask = self.transformer.generate_square_subsequent_mask(tgt.size(1)).to(tgt.device)\n",
    "        src_mask = (src == 0).unsqueeze(1).unsqueeze(2).expand(-1, self.nhead, D_MODEL, -1)\n",
    "        src_mask = src_mask.reshape(src.size(0)*self.nhead, D_MODEL, D_MODEL)\n",
    "\n",
    "        output = self.transformer(src_emb, tgt_emb, src_mask=src_mask, tgt_mask=tgt_mask)\n",
    "        return self.fc_out(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.serialization.add_safe_globals([TransformerModel])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "actn6o_k28pp"
   },
   "source": [
    "# Le dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trouver un dataset médical complet est compliqué. Nous cherchions un dataset qui associe des symptômes à un diagnostic possible. Exemple : \n",
    "- les symptômes : forte fièvre, douleurs musculaires, frissons, fatigue\n",
    "- la maladie possible : la grippe\n",
    "\n",
    "Nous avons rapidement exclut de créer le dataset puisque cela nécessite soit de nombreuses connaissances en médecine, soit un temps très important pour chercher un ensemble de maladies possibles et lui associer \"à la main\" tous les symptômes les plus fréquents. \n",
    "\n",
    "Nous avons opté pour une sorte de mélange : \n",
    "- nous avons récupéré un [dataset](https://www.geeksforgeeks.org/talking-healthcare-chatbot-using-deep-learning/)\n",
    "- nous avons ajouté des symptômes et des maladies à la main pour l'enrichir un petit peu\n",
    "\n",
    "Notre dataset est \"petit\" : \n",
    "on a 124 maladies possibles, et pour chacune on a entre 3 et 11 symptômes ainsi que 2 ou 3 réponses possibles. \n",
    "Nous avons donc fait toutes les combinaisons possibles des symptômes avec les réponses correspondantes, et on obtient un peu plus de 2300 données.\n",
    "\n",
    "Travailler avec un petit dataset a été un réel challenge, et si nous avions eu plus de temps, nous aurions aimé pouvoir l'enrichir encore davantage!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "3o89aREJV2ok"
   },
   "outputs": [],
   "source": [
    "def load_dataset(filename, tokenizer):\n",
    "    data = pd.read_csv(filename)\n",
    "\n",
    "    dataset_src = []\n",
    "    dataset_tgt = []\n",
    "\n",
    "\n",
    "    for index, row in data.iterrows():\n",
    "        row_patterns = [row[col] for col in row.index if \"intents/patterns\" in col and pd.notna(row[col])]\n",
    "        row_responses = [row[col] for col in row.index if \"intents/responses\" in col and pd.notna(row[col])]\n",
    "\n",
    "        for response in row_responses:\n",
    "            for pattern in row_patterns:\n",
    "                dataset_src.append(tokenizer.encode(pattern, should_extend=True))\n",
    "                dataset_tgt.append(tokenizer.encode(response, should_extend=True))\n",
    "\n",
    "            dataset_src.append(tokenizer.encode(\"i have \"+\" and \".join(row_patterns), should_extend=True))\n",
    "            dataset_tgt.append(tokenizer.encode(response, should_extend=True))\n",
    "\n",
    "    return torch.tensor(dataset_src), torch.tensor(dataset_tgt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrainement du modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On définit ensuite notre fonction d'apprentissage.\n",
    "\n",
    "Nous avons opté pour 1000 epochs et un apprentissage par batch de taille 200 avec permutation aléatoire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "aZwiXhs9zwYT"
   },
   "outputs": [],
   "source": [
    "def train_model(model, dataset_src, dataset_tgt, vocab_size, pad_id):\n",
    "    criterion = torch.nn.CrossEntropyLoss(ignore_index=pad_id)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    epochs = 1000\n",
    "    batch_size = 200\n",
    "\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "\n",
    "        permutation = torch.randperm(dataset_src.size()[0])\n",
    "\n",
    "        for i in range(0, len(dataset_src), batch_size):\n",
    "            indices = permutation[i:i+batch_size]\n",
    "            src_batch = dataset_src[indices]\n",
    "            tgt_batch = dataset_tgt[indices]\n",
    "\n",
    "            decoder_input = tgt_batch[:, :-1]  # Entrée du décodeur (sans le dernier token)\n",
    "            decoder_target = tgt_batch[:, 1:]  # Cible (sans le premier token)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(src_batch, decoder_input)\n",
    "            loss = criterion(output.view(-1, vocab_size), decoder_target.reshape(-1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {epoch+1}, Loss: {epoch_loss / len(dataset_src)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On combine ensuite le tout pour que notre modèle apprenne avec notre dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "qtx_RPo5Wb1I"
   },
   "outputs": [],
   "source": [
    "dataset_file = \"./dataset.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "dataset_src, dataset_tgt = load_dataset(dataset_file, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TransformerModel(tokenizer.vocab_size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MzeH-vtwzWGw",
    "outputId": "94e97566-e9ac-4a79-a549-cdc17bbc0f51",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "\n",
    "dataset_src = dataset_src.to(device)\n",
    "dataset_tgt = dataset_tgt.to(device)\n",
    "model = model.to(device)\n",
    "\n",
    "train_model(model, dataset_src, dataset_tgt, tokenizer.vocab_size(), tokenizer.pad_token_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Voici la courbe d'apprentissage de notre modèle sur 1000 epochs.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            0\n",
      "0    0.032375\n",
      "1    0.027359\n",
      "2    0.022264\n",
      "3    0.019253\n",
      "4    0.017256\n",
      "..        ...\n",
      "995  0.000952\n",
      "996  0.000945\n",
      "997  0.000937\n",
      "998  0.000926\n",
      "999  0.000920\n",
      "\n",
      "[1000 rows x 1 columns]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = pd.read_csv(\"./teaching.txt\", header=None)\n",
    "print(data)\n",
    "plt.yscale('logit')\n",
    "plt.plot(data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sauvegarde et chargement du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "t3EbLLJz3cll"
   },
   "outputs": [],
   "source": [
    "torch.save(model, \"medbot.pt\")\n",
    "tokenizer.save(\"tokenizer.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "mF6IC7ISks0k"
   },
   "outputs": [],
   "source": [
    "model = torch.load(\"medbot.pt\", weights_only=False, map_location=torch.device('cpu'))\n",
    "tokenizer = Tokenizer(\"tokenizer.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "86zgYcKZCSU1"
   },
   "source": [
    "\n",
    "# Utilisation du modèle\n",
    "\n",
    "La fonction `top_k_sampling` permet de choisir un token parmis les **k** meilleurs. Cela donne un aspect aléatoire à la phrase construite par le modèle.\n",
    "\n",
    "Pour ce faire, nous prenons les k tokens avec le meilleur score. Nous transformons les scores en probabilité à l'aide de la fonction **softmax**. Nous tirons un token aléatoirement parmi les k en fonction de leur probabilité respective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_k_sampling(logits, k=3):\n",
    "    top_k_probs, top_k_indices = torch.topk(torch.softmax(logits, dim=-1), k=k)\n",
    "    idx = torch.multinomial(top_k_probs, num_samples=1)\n",
    "    next_token = top_k_indices[idx]\n",
    "    probability = top_k_probs[idx]\n",
    "    return next_token, probability.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons alors générer une phrase avec notre modèle :\n",
    "- La phrase source est transformée en tokens via notre tokenizer\n",
    "- La phrase de sortie est initialisée avec le token **CLS** de notre tokenizer\n",
    "- À chaque itération, nous donnons la phrase source et la phrase de sortie à notre modèle\n",
    "- Un token est alors choisi aléatoirement avec `top_k_sampling` à partir des scores retournés par le modèle\n",
    "- On ajoute ce token à la phrase de sortie\n",
    "- Lorsque nous rencontrons le token **SEP** (ou que la taille maximale est atteinte), la phrase de sortie est finie et nous la décodons avec le tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "dHXFMKds0QKJ"
   },
   "outputs": [],
   "source": [
    "def valid_tokens(tokens, tokenizer):\n",
    "    for token in tokens:\n",
    "        if token not in tokenizer.special_tokens:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def generate_answer(model, sentence, tokenizer, skip_special_tokens=False, max_len=64):\n",
    "    model.to('cpu')\n",
    "    model.eval()\n",
    "    src_tokens = tokenizer.encode(sentence)\n",
    "    if not valid_tokens(src_tokens, tokenizer):\n",
    "      return \"I did not understand.\"\n",
    "    src = torch.tensor(src_tokens).unsqueeze(0)\n",
    "    tgt = torch.tensor([tokenizer.cls_token_id]).unsqueeze(0)\n",
    "\n",
    "    first_word_probability = None\n",
    "    for _ in range(max_len):\n",
    "        output = model(src, tgt)\n",
    "        next_token, probability = top_k_sampling(output[0, -1, :])\n",
    "        if _ == 0: first_word_probability = probability\n",
    "        tgt = torch.cat([tgt, torch.tensor([[next_token]])], dim=1)\n",
    "        if next_token == tokenizer.sep_token_id:\n",
    "            break\n",
    "\n",
    "    return tokenizer.decode(tgt[0], skip_special_tokens=skip_special_tokens), first_word_probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici, nous testons la génération de phrases en donner au modèle différents inputs. Pour chaque input, nous avons la phrase générée ainsi que la probabilité de son premier mot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input : hello\n",
      "(31.4%) [CLS] hello! [SEP]\n",
      "\n",
      "input : i have fever\n",
      "(25.7%) [CLS] according to your symptoms you might have hepatitis a [SEP]\n",
      "\n",
      "input : thank you\n",
      "(28.2%) [CLS] talk to you later! [SEP]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_sentences = [\n",
    "    \"hello\",\n",
    "    \"i have fever\",\n",
    "    \"thank you\"\n",
    "]\n",
    "\n",
    "for sentence in test_sentences:\n",
    "    answer, probability = generate_answer(model, sentence, tokenizer)\n",
    "    print(\"input :\", sentence)\n",
    "    print(f\"({probability*100:3.1f}%)\", answer)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Le chabot interactif final\n",
    "Pour finir, le chatbot peut être testé interactivement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "drHUlwXI0VEy"
   },
   "outputs": [],
   "source": [
    "def chat_with_bot(model, tokenizer):\n",
    "    print(\"[Start of conversation]\")\n",
    "    print(\"medbot: Hello, I am Medbot.\")\n",
    "    print(\"        You can stop the chat by typing 'quit', 'exit' or simply 'q'.\")\n",
    "    print(\"        Please tell me your symptoms.\")\n",
    "    while True:\n",
    "        txt = input(\"user: \").strip()\n",
    "        if txt in [\"q\", \"quit\", \"exit\"]: break\n",
    "        answer, probability = generate_answer(model, txt, tokenizer, skip_special_tokens=True)\n",
    "        print(\"medbot:\", answer)\n",
    "    print(\"[End of conversation]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MPatJ1yw3YLg",
    "outputId": "8f80774b-e19f-4bc9-b3e4-e580101b6d5d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Start of conversation]\n",
      "medbot: Hello, I am Medbot.\n",
      "        You can stop the chat by typing 'quit', 'exit' or simply 'q'.\n",
      "        Please tell me your symptoms.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "user:  hello\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "medbot: hello, what can i do for you?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "user:  i have difficulty swallowing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "medbot: i suppose you have iron deficiency anaemia\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "user:  i also have jaw locking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "medbot: have you been vaccinated against tetanus?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "user:  Thank You, Goodbye\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "medbot: thank you to you too\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "user:  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[End of conversation]\n"
     ]
    }
   ],
   "source": [
    "chat_with_bot(model, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Améliorations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons pensé à quelques améliorations.\n",
    "\n",
    "## **enrichissement du dataset**\n",
    "Comme mentionné dans l'introduction, un des principaux problèmes que nous rencontrons est lié au fait que le dataset soit trop petit. Une des améliorations évidentes serait de l'enrichir considérablement, notamment en termes médicaux mais également avec des termes de la vie courante tels que les conjugaisons des mots, des formulations familières etc... afin que le chatbot puisse comprendre des phrases plus complexes.\n",
    "\n",
    "## **la gestion d'une session**\n",
    "Notre chatbot ne comprend actuellement qu'une phrase, et l'oublie une fois que l'utilisateur en saisit une autre. \n",
    "Notre idée aurait été d'avoir une mémoire lors d'une session de telle sorte que, tout ce qu'aurait dit un utilisateur entre sa connexion et le moment où il quitte, soit pris en compte lors de la réponse du chatbot.\n",
    "Ainsi, l'utilisateur pourrait préciser ses symptômes au fur et à mesure de la discussion, et le chatbot pourrait ajuster ses réponses.\n",
    "\n",
    "## **la confiance du modèle**\n",
    "Aujourd'hui, notre modèle répond, quelque soit son niveau de confiance. \n",
    "On note deux sortes de cas :\n",
    "\n",
    "**Problème 1 :** l'utilisateur entre un symptôme qui est commun à plusieurs maladies : le chatbot donnera un diagnostic de maladie qui contient ce symptôme.  \n",
    "**Amélioration :** idéalement, s'il ne sait pas se décider, le chatbot devrait demander à l'utilisateur de lui donner d'autres symptômes afin d'affiner son diagnostic et pouvoir répondre avec un certain degré de confiance\n",
    "\n",
    "**Problème 2 :** lorsque l'utilisateur donne une phrase qui contient des tokens inconnus associés à des tokens connus, le chatbot répondra quelque chose de sûrement incohérent. Par exemple, si l'utilisateur dit \"I have a cat\", le chatbot reconnaîtra \"I have\" puisque cela fait partit de son vocabulaire, mais il ne connaît pas le \"a cat\". Malheureusement, pour le moment, le chatbot peut répondre que vous êtes probablement atteint d'un cancer.  \n",
    "**Amélioration :** il faudrait que notre modèle arrive à gérer ce genre de cas, et puisse fournir une réponse adaptée (soit il ne comprend pas la phrase et demande des précisions, soit informe qu'il ne comprend pas, soit arrive à extraire les informations pertinentes et si elles sont suffisantes, donne une réponse cohérente).   \n",
    "\n",
    "Toutefois, si le chatbot ne reconnaît aucun mot, il informera l'utilisateur qu'il n'a pas compris sa phrase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bien que nos ressources (en termes de GPU et de nombre de données) soient limitées, nous sommes contents d'avoir réussit à entraîner notre premier modèle et de pouvoir échanger avec un chatbot.\n",
    "Ce projet nous a permis de mieux comprendre le Transformer, bien que vu en cours, et de saisir l'importance de chaque étape (tokenisation, embedding etc...). \n",
    "Nous sommes presque déçus que le projet ne dure pas plus longtemps car nous trouvons celui-ci ludique et intéressant!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "medbot: goodbye!\n"
     ]
    }
   ],
   "source": [
    "print(\"medbot:\", generate_answer(model, \"Bye\", tokenizer, skip_special_tokens=True)[0])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
